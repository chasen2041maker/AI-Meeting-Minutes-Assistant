# AI 会议记录项目 - 技术调研文档

## 一、项目核心功能分析

### 1.1 功能优先级矩阵

| 优先级 | 功能模块 | 技术依赖 | 复杂度 |
|--------|----------|----------|--------|
| **P0** | 音频上传 + Whisper 转写 | Whisper API | ⭐⭐ |
| **P0** | 文字摘要生成 | Chat API | ⭐⭐ |
| **P0** | 前端上传展示 | React/HTML | ⭐ |
| **P1** | 浏览器内录音 | MediaRecorder API | ⭐⭐⭐ |
| **P1** | 结构化输出（摘要/决定/行动项） | Prompt Engineering | ⭐⭐ |
| **P2** | 导出 Markdown/PDF | 文件生成库 | ⭐⭐ |
| **P2** | 说话人识别 | Whisper diarization | ⭐⭐⭐⭐ |

### 1.2 数据流架构

```
┌─────────────────────────────────────────────────────────────────┐
│                        用户界面层                                │
│  ┌──────────────┐    ┌──────────────┐    ┌──────────────┐       │
│  │  上传音频    │    │  浏览器录音   │    │  结果展示    │       │
│  └──────┬───────┘    └──────┬───────┘    └──────▲───────┘       │
└─────────┼───────────────────┼───────────────────┼───────────────┘
          │                   │                   │
          ▼                   ▼                   │
┌─────────────────────────────────────────────────┴───────────────┐
│                        后端 API 层                               │
│  ┌──────────────────────┐    ┌──────────────────────┐           │
│  │  POST /transcribe    │───▶│  POST /summarize     │           │
│  │  音频 → 文字         │    │  文字 → 摘要         │           │
│  └──────────┬───────────┘    └──────────┬───────────┘           │
└─────────────┼────────────────────────────┼──────────────────────┘
              │                            │
              ▼                            ▼
┌─────────────────────────────────────────────────────────────────┐
│                      外部服务层                                  │
│  ┌──────────────────────┐    ┌──────────────────────┐           │
│  │  OpenAI Whisper API  │    │  OpenAI Chat API     │           │
│  │  $0.006/分钟         │    │  GPT-4o / GPT-4o-mini│           │
│  └──────────────────────┘    └──────────────────────┘           │
└─────────────────────────────────────────────────────────────────┘
```

---

## 二、技术选型调研

### 2.1 OpenAI Whisper API

#### 基本信息
- **端点**: `https://api.openai.com/v1/audio/transcriptions`
- **定价**: $0.006/分钟（约 ¥0.04/分钟）
- **模型**: `whisper-1`
- **最大文件**: 25MB
- **支持格式**: `mp3`, `mp4`, `mpeg`, `mpga`, `m4a`, `wav`, `webm`

#### 调用示例（Node.js）

```javascript
import OpenAI from 'openai';
import fs from 'fs';

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY
});

async function transcribeAudio(filePath) {
  const transcription = await openai.audio.transcriptions.create({
    file: fs.createReadStream(filePath),
    model: 'whisper-1',
    language: 'zh',  // 可选：指定语言提高准确度
    response_format: 'json',  // 可选：json, text, srt, verbose_json, vtt
    timestamp_granularities: ['segment']  // 可选：获取时间戳
  });
  
  return transcription.text;
}
```

#### 调用示例（Python）

```python
from openai import OpenAI

client = OpenAI()

def transcribe_audio(file_path):
    with open(file_path, "rb") as audio_file:
        transcription = client.audio.transcriptions.create(
            model="whisper-1",
            file=audio_file,
            language="zh",
            response_format="verbose_json",
            timestamp_granularities=["segment"]
        )
    return transcription
```

#### 重要参数说明

| 参数 | 类型 | 说明 |
|------|------|------|
| `file` | File | 必需，音频文件 |
| `model` | string | 必需，目前只有 `whisper-1` |
| `language` | string | ISO-639-1 格式，如 `zh`、`en` |
| `response_format` | string | `json`/`text`/`srt`/`verbose_json`/`vtt` |
| `prompt` | string | 可选，提供上下文提高准确度 |
| `temperature` | number | 0-1，控制输出随机性 |

#### 处理大文件（>25MB）

```javascript
import { exec } from 'child_process';
import { promisify } from 'util';

const execAsync = promisify(exec);

async function splitAudio(inputPath, chunkDurationSec = 600) {
  // 使用 ffmpeg 分割音频为 10 分钟片段
  const outputPattern = `${inputPath.replace(/\.[^/.]+$/, '')}_chunk_%03d.mp3`;
  await execAsync(
    `ffmpeg -i ${inputPath} -f segment -segment_time ${chunkDurationSec} -c copy ${outputPattern}`
  );
  // 返回分割后的文件列表
}
```

---

### 2.2 OpenAI Chat API（摘要生成）

#### 基本信息
- **推荐模型**: `gpt-4o-mini`（性价比最高）或 `gpt-4o`（质量最好）
- **定价**: 
  - GPT-4o-mini: $0.15/1M 输入 + $0.60/1M 输出
  - GPT-4o: $2.50/1M 输入 + $10/1M 输出

#### 结构化输出的 System Prompt

```javascript
const SYSTEM_PROMPT = `你是一个专业的会议记录助手。请分析以下会议转写文本，并生成结构化的会议记录。

请严格按照以下 JSON 格式输出，不要包含任何其他文字：

{
  "summary": "会议摘要（100-200字）",
  "key_decisions": [
    "关键决定1",
    "关键决定2"
  ],
  "action_items": [
    {
      "assignee": "负责人姓名",
      "task": "具体任务内容",
      "deadline": "截止时间（如有提及）"
    }
  ],
  "participants": ["参会人员列表（如能识别）"],
  "topics_discussed": ["讨论主题1", "讨论主题2"]
}

注意事项：
1. 如果无法识别某些信息，对应字段返回空数组或 "未提及"
2. 行动项必须包含明确的负责人和任务
3. 摘要要简洁但涵盖主要内容`;
```

#### 调用示例

```javascript
async function generateSummary(transcriptText) {
  const response = await openai.chat.completions.create({
    model: 'gpt-4o-mini',
    response_format: { type: 'json_object' },  // 强制 JSON 输出
    messages: [
      { role: 'system', content: SYSTEM_PROMPT },
      { role: 'user', content: `请分析以下会议内容：\n\n${transcriptText}` }
    ],
    temperature: 0.3,  // 低温度确保输出稳定
    max_tokens: 2000
  });
  
  return JSON.parse(response.choices[0].message.content);
}
```

---

### 2.3 浏览器录音（MediaRecorder API）

#### 基本实现

```javascript
class AudioRecorder {
  constructor() {
    this.mediaRecorder = null;
    this.audioChunks = [];
  }

  async start() {
    const stream = await navigator.mediaDevices.getUserMedia({ 
      audio: {
        echoCancellation: true,
        noiseSuppression: true,
        sampleRate: 44100
      } 
    });
    
    // 优先使用 webm（兼容性好），备选 mp4
    const mimeType = MediaRecorder.isTypeSupported('audio/webm;codecs=opus')
      ? 'audio/webm;codecs=opus'
      : 'audio/mp4';
    
    this.mediaRecorder = new MediaRecorder(stream, { mimeType });
    this.audioChunks = [];
    
    this.mediaRecorder.ondataavailable = (event) => {
      if (event.data.size > 0) {
        this.audioChunks.push(event.data);
      }
    };
    
    this.mediaRecorder.start(1000); // 每秒收集一次数据
  }

  stop() {
    return new Promise((resolve) => {
      this.mediaRecorder.onstop = () => {
        const audioBlob = new Blob(this.audioChunks, { 
          type: this.mediaRecorder.mimeType 
        });
        resolve(audioBlob);
      };
      this.mediaRecorder.stop();
      this.mediaRecorder.stream.getTracks().forEach(track => track.stop());
    });
  }
}
```

#### 注意事项
- 需要 HTTPS 环境（localhost 除外）
- 用户必须授权麦克风权限
- `webm` 格式 Whisper API 直接支持

---

## 三、API 设计方案

### 3.1 接口规范

#### 1. 音频转写接口

```
POST /api/transcribe
Content-Type: multipart/form-data
```

**请求参数：**
| 参数 | 类型 | 必需 | 说明 |
|------|------|------|------|
| `audio` | File | 是 | 音频文件 |
| `language` | string | 否 | 语言代码，默认自动检测 |

**响应示例：**
```json
{
  "success": true,
  "data": {
    "text": "会议转写的完整文本...",
    "duration": 1234.5,
    "language": "zh"
  }
}
```

#### 2. 摘要生成接口

```
POST /api/summarize
Content-Type: application/json
```

**请求参数：**
```json
{
  "text": "需要分析的会议文本",
  "options": {
    "include_action_items": true,
    "include_decisions": true,
    "summary_length": "medium"
  }
}
```

**响应示例：**
```json
{
  "success": true,
  "data": {
    "summary": "本次会议讨论了...",
    "key_decisions": ["决定1", "决定2"],
    "action_items": [
      {
        "assignee": "张三",
        "task": "提交方案",
        "deadline": "下周一"
      }
    ],
    "participants": ["张三", "李四"],
    "topics_discussed": ["预算", "渠道"]
  }
}
```

#### 3. 一键处理接口（可选）

```
POST /api/process
Content-Type: multipart/form-data
```

将转写和摘要合并为一个接口，减少前端调用次数。

---

### 3.2 后端代码结构（Node.js + Express）

```
backend/
├── src/
│   ├── index.js              # 入口文件
│   ├── routes/
│   │   └── meeting.js        # 会议相关路由
│   ├── controllers/
│   │   └── meetingController.js
│   ├── services/
│   │   ├── whisperService.js # Whisper API 封装
│   │   └── summaryService.js # Chat API 封装
│   └── utils/
│       └── fileHandler.js    # 文件处理工具
├── uploads/                   # 临时上传目录
├── .env                       # 环境变量
└── package.json
```

---

## 四、推荐技术栈

### 4.1 后端技术栈

| 技术 | 用途 | 理由 |
|------|------|------|
| **Node.js + Express** | Web 服务器 | 生态成熟，异步处理音频友好 |
| **Multer** | 文件上传 | Express 标准文件上传中间件 |
| **OpenAI SDK** | API 调用 | 官方 SDK，类型完善 |
| **dotenv** | 环境变量 | 管理 API Key |
| **ffmpeg** | 音频处理 | 大文件分割、格式转换 |

### 4.2 前端技术栈

| 技术 | 用途 | 理由 |
|------|------|------|
| **React / Next.js** | 前端框架 | 或使用 Figma Make 生成 |
| **Tailwind CSS** | 样式 | 快速开发 |
| **Axios** | HTTP 请求 | 文件上传进度支持好 |

### 4.3 依赖清单

```json
{
  "dependencies": {
    "express": "^4.18.2",
    "multer": "^1.4.5-lts.1",
    "openai": "^4.20.0",
    "dotenv": "^16.3.1",
    "cors": "^2.8.5"
  },
  "devDependencies": {
    "nodemon": "^3.0.1"
  }
}
```

---

## 五、开发步骤与里程碑

### 阶段一：后端核心功能（Week 2）

#### Step 1: 项目初始化
```bash
mkdir meeting-notes-backend && cd meeting-notes-backend
npm init -y
npm install express multer openai dotenv cors
```

**验收标准：** 
- [ ] 项目结构创建完成
- [ ] 环境变量配置完成
- [ ] Express 服务器可以启动

#### Step 2: Whisper 转写服务
**开发内容：**
1. 创建 `/api/transcribe` 路由
2. 使用 Multer 接收音频文件
3. 调用 Whisper API 返回文字

**验收标准：**
- [ ] 能上传 mp3/wav/webm 文件
- [ ] 返回正确的转写文本
- [ ] 错误处理完善（文件过大、格式错误等）

**测试方法：**
```bash
curl -X POST http://localhost:3000/api/transcribe \
  -F "audio=@test.mp3"
```

#### Step 3: 摘要生成服务
**开发内容：**
1. 创建 `/api/summarize` 路由
2. 设计 System Prompt
3. 使用 JSON mode 确保结构化输出

**验收标准：**
- [ ] 输入文本返回 JSON 格式摘要
- [ ] 包含 summary、key_decisions、action_items
- [ ] 中英文都能正确处理

---

### 阶段二：前端集成（Week 3）

#### Step 4: 前端基础界面
**使用 Figma Make 或手写：**
1. 文件上传组件（支持拖拽）
2. 结果展示区域
3. 加载状态提示

**验收标准：**
- [ ] 能选择/拖拽上传音频文件
- [ ] 显示上传进度
- [ ] 展示转写结果和摘要

#### Step 5: 浏览器录音功能（P1）
**开发内容：**
1. 实现 MediaRecorder 录音
2. 录音状态 UI（录音中、已停止）
3. 录音完成自动上传

**验收标准：**
- [ ] 点击按钮开始/停止录音
- [ ] 显示录音时长
- [ ] 录音文件能正确上传处理

---

### 阶段三：优化与完善（Week 4）

#### Step 6: 用户体验优化
- 处理过程进度提示
- 错误信息友好展示
- 历史记录存储（localStorage）

#### Step 7: 可选功能
- Markdown 导出
- 复制到剪贴板
- 响应式设计

**最终验收标准：**
- [ ] 完整演示：上传→转写→摘要
- [ ] 录音演示：录制→处理→展示
- [ ] 边界情况处理完善

---

## 六、从哪个模块开始？

### 推荐顺序：后端 → 前端 → 优化

```
第一步：Whisper 转写服务
     ↓
第二步：Chat 摘要服务
     ↓
第三步：前端上传界面
     ↓
第四步：浏览器录音
     ↓
第五步：导出功能
```

### 理由

1. **后端先行**：确保核心 API 可用，前端才有数据可展示
2. **先转写后摘要**：转写是基础，摘要依赖转写结果
3. **前端最后**：可以用 Postman/curl 测试后端，前端可以用 Figma Make 快速生成

### 第一个要写的文件

```javascript
// src/services/whisperService.js
import OpenAI from 'openai';
import fs from 'fs';

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY
});

export async function transcribe(filePath) {
  try {
    const transcription = await openai.audio.transcriptions.create({
      file: fs.createReadStream(filePath),
      model: 'whisper-1',
      response_format: 'json'
    });
    return { success: true, text: transcription.text };
  } catch (error) {
    return { success: false, error: error.message };
  }
}
```

---

## 七、风险与注意事项

### 7.1 技术风险

| 风险 | 影响 | 缓解措施 |
|------|------|----------|
| 音频文件过大 | API 拒绝 | 前端限制 + 后端分片 |
| API 调用失败 | 功能不可用 | 重试机制 + 错误提示 |
| 转写不准确 | 摘要质量差 | 支持手动编辑 |

### 7.2 成本预估

假设每次会议 30 分钟：
- Whisper：$0.006 × 30 = **$0.18/次**
- Chat API（GPT-4o-mini）：约 **$0.01/次**
- **总计：约 $0.19/次 ≈ ¥1.4/次**

### 7.3 安全注意

- API Key 绝不能暴露在前端
- 上传文件需要类型和大小校验
- 考虑添加用户认证（如需上线）

---

## 八、参考资料

1. [OpenAI Whisper API 文档](https://platform.openai.com/docs/guides/speech-to-text)
2. [OpenAI Chat Completions API](https://platform.openai.com/docs/guides/text-generation)
3. [MDN MediaRecorder API](https://developer.mozilla.org/en-US/docs/Web/API/MediaRecorder)
4. [Meeting Minutes Tutorial - OpenAI Cookbook](https://cookbook.openai.com/examples/meeting_minutes)
5. [Multer 文件上传](https://github.com/expressjs/multer)

---

**文档版本**: v1.0  
**最后更新**: 2025年1月  
**状态**: 待导师审核
